{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff2b7fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import io\n",
    "import imageio\n",
    "from IPython.display import Image, display\n",
    "from ipywidgets import widgets, Layout, HBox\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ad2746",
   "metadata": {},
   "source": [
    "# No_Overlapping_Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "589bae98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9024\n",
      "(376, 24, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "path = './radar_images'\n",
    "image = []\n",
    "num_frame = 24\n",
    "image_files = sorted(os.listdir(path))\n",
    "num_samples = len(image_files) // num_frame\n",
    "c = 0\n",
    "for i in range(num_samples):\n",
    "    sample = []\n",
    "    for j in range(num_frame):\n",
    "        file_index = i * num_frame + j\n",
    "#         print(\"file_index-->\", file_index)\n",
    "        file_name = image_files[file_index]\n",
    "#         print(\"file_name---->\", file_name)\n",
    "        if file_name.endswith('png'):\n",
    "            img = load_img(path + '/' + file_name, color_mode='rgb')\n",
    "            img = img_to_array(img)\n",
    "            img = cv2.resize(img, (64,64))\n",
    "            sample.append(img)\n",
    "            c += 1\n",
    "#         print(\"end of frame\")\n",
    "    image.append(sample)\n",
    "#     print(\"end of sample\")\n",
    "print(c)\n",
    "dataset = np.array(image)\n",
    "\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e425d4",
   "metadata": {},
   "source": [
    "# Overlapping_Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93075c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 24, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "path = './radar_images'\n",
    "\n",
    "image_files = sorted(os.listdir(path))\n",
    "image = []\n",
    "\n",
    "# Load the images.\n",
    "for i in range(0, len(image_files) - 24, 1):\n",
    "    window = image_files[i:i + 24]\n",
    "    sample = []\n",
    "    for file_name in window:\n",
    "        if file_name.endswith('png'):\n",
    "#             print(file_name)\n",
    "            img = cv2.imread(path + '/' + file_name)\n",
    "            img = cv2.resize(img, (64, 64))\n",
    "            sample.append(img)\n",
    "    image.append(sample)\n",
    "dataset = np.array(image)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5607c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Shapes: (6300, 12, 64, 64, 3), (6300, 12, 64, 64, 3)\n",
      "Validation Dataset Shapes: (1800, 12, 64, 64, 3), (1800, 12, 64, 64, 3)\n",
      "Test Dataset Shapes: (900, 12, 64, 64, 3), (900, 12, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split into train and validation sets using indexing to optimize memory.\n",
    "indexes = np.arange(dataset.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "train_index = indexes[: int(0.7 * dataset.shape[0])]\n",
    "val_index = indexes[int(0.7 * dataset.shape[0]):int(0.9 * dataset.shape[0])]\n",
    "test_index = indexes[int(0.9 * dataset.shape[0]):]\n",
    "train_dataset = dataset[train_index]\n",
    "val_dataset = dataset[val_index]\n",
    "test_dataset = dataset[test_index]\n",
    "\n",
    "# Normalize the data to the 0-1 range.\n",
    "train_dataset = train_dataset / 255\n",
    "val_dataset = val_dataset / 255\n",
    "test_dataset = test_dataset / 255\n",
    "\n",
    "# Create input(x) and label(y)\n",
    "def create_shifted_frames(data):\n",
    "    x = data[:, 0 : data.shape[1] - 12, :, :]\n",
    "    y = data[:, 12 : data.shape[1], :, :]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# Apply the processing function to the datasets.\n",
    "x_train, y_train = create_shifted_frames(train_dataset)\n",
    "x_val, y_val = create_shifted_frames(val_dataset)\n",
    "x_test, y_test = create_shifted_frames(test_dataset)\n",
    "\n",
    "# Inspect the dataset.\n",
    "print(\"Training Dataset Shapes: \" + str(x_train.shape) + \", \" + str(y_train.shape))\n",
    "print(\"Validation Dataset Shapes: \" + str(x_val.shape) + \", \" + str(y_val.shape))\n",
    "print(\"Test Dataset Shapes: \" + str(x_test.shape) + \", \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10239edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataset\n",
    "with h5py.File('./dataset/12framesRGB_overlap.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"train\", data=train_dataset)\n",
    "    hf.create_dataset(\"val\", data=val_dataset)\n",
    "    hf.create_dataset(\"test\", data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47493f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "with h5py.File('./dataset/12framesRGB_overlap.h5', 'r') as hf:\n",
    "    train_dataset = hf[\"train\"][:]\n",
    "    val_dataset = hf[\"val\"][:]\n",
    "    test_dataset = hf[\"test\"][:]\n",
    "\n",
    "# Create input(x) and label(y)\n",
    "def create_shifted_frames(data):\n",
    "    x = data[:, 0 : data.shape[1] - 12, :, :]\n",
    "    y = data[:, 12 : data.shape[1], :, :]\n",
    "    return x, y\n",
    "\n",
    "# Apply the processing function to the datasets.\n",
    "x_train, y_train = create_shifted_frames(train_dataset)\n",
    "x_val, y_val = create_shifted_frames(val_dataset)\n",
    "x_test, y_test = create_shifted_frames(test_dataset)\n",
    "\n",
    "# Inspect the dataset.\n",
    "print(\"Training Dataset Shapes: \" + str(x_train.shape) + \", \" + str(y_train.shape))\n",
    "print(\"Validation Dataset Shapes: \" + str(x_val.shape) + \", \" + str(y_val.shape))\n",
    "print(\"Test Dataset Shapes: \" + str(x_test.shape) + \", \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7aff3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating output folder\n",
    "output_dir = './output/WP_12framesconvLSTM_overlap_d3'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3d78a9",
   "metadata": {},
   "source": [
    "# Building the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83a4427c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/anaconda3/envs/gt/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/gt/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Construct the input layer with no definite frame size.\n",
    "inp = layers.Input(shape=(None, *x_train.shape[2:]))\n",
    "\n",
    "x = layers.ConvLSTM2D(\n",
    "    filters=32,\n",
    "    kernel_size=(3, 3),\n",
    "    padding=\"same\",\n",
    "    dilation_rate=(3, 3),\n",
    "    return_sequences=True,\n",
    "    activation=\"relu\",\n",
    ")(inp)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ConvLSTM2D(\n",
    "    filters=64,\n",
    "    kernel_size=(3, 3),\n",
    "    padding=\"same\",\n",
    "    dilation_rate=(3, 3),\n",
    "    return_sequences=True,\n",
    "    activation=\"relu\",\n",
    ")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ConvLSTM2D(\n",
    "    filters=128,\n",
    "    kernel_size=(1, 1),\n",
    "    padding=\"same\",\n",
    "    dilation_rate=(3, 3),\n",
    "    return_sequences=True,\n",
    "    activation=\"relu\",\n",
    ")(x)\n",
    "x = layers.Conv3D(\n",
    "    filters=3, kernel_size=(3, 3, 3), activation=\"sigmoid\", padding=\"same\"\n",
    ")(x)\n",
    "\n",
    "# Next, we will build the complete model and compile it.\n",
    "model = keras.models.Model(inp, x)\n",
    "model.compile(\n",
    "    loss=keras.losses.binary_crossentropy, \n",
    "    optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "    metrics=[\"accuracy\", \"mean_squared_error\", \"mean_absolute_error\"]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817c92fa",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655ba73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6300 samples, validate on 1800 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-19 10:26:39.431233: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2024-10-19 10:26:39.486451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-19 10:26:39.488049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: Quadro P5000 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:02:00.0\n",
      "2024-10-19 10:26:39.488139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-19 10:26:39.488308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: Quadro P5000 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:03:00.0\n",
      "2024-10-19 10:26:39.489719: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/user/anaconda3/envs/gt/lib/python3.7/site-packages/cv2/../../lib64:/usr/local/cuda-11.5/lib64:\n",
      "2024-10-19 10:26:39.491059: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/user/anaconda3/envs/gt/lib/python3.7/site-packages/cv2/../../lib64:/usr/local/cuda-11.5/lib64:\n",
      "2024-10-19 10:26:39.491349: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/user/anaconda3/envs/gt/lib/python3.7/site-packages/cv2/../../lib64:/usr/local/cuda-11.5/lib64:\n",
      "2024-10-19 10:26:39.491623: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/user/anaconda3/envs/gt/lib/python3.7/site-packages/cv2/../../lib64:/usr/local/cuda-11.5/lib64:\n",
      "2024-10-19 10:26:39.491827: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/user/anaconda3/envs/gt/lib/python3.7/site-packages/cv2/../../lib64:/usr/local/cuda-11.5/lib64:\n",
      "2024-10-19 10:26:39.492116: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/user/anaconda3/envs/gt/lib/python3.7/site-packages/cv2/../../lib64:/usr/local/cuda-11.5/lib64:\n",
      "2024-10-19 10:26:39.493610: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/user/anaconda3/envs/gt/lib/python3.7/site-packages/cv2/../../lib64:/usr/local/cuda-11.5/lib64:\n",
      "2024-10-19 10:26:39.493624: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-10-19 10:26:39.496611: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2024-10-19 10:26:39.584457: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2194680000 Hz\n",
      "2024-10-19 10:26:39.590333: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2350000 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-10-19 10:26:39.590360: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-10-19 10:26:39.970115: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-19 10:26:39.974008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-19 10:26:39.974590: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2108560 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-10-19 10:26:39.974634: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro P5000, Compute Capability 6.1\n",
      "2024-10-19 10:26:39.974647: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Quadro P5000, Compute Capability 6.1\n",
      "2024-10-19 10:26:39.975329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-10-19 10:26:39.975358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-19 10:26:43.571260: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 679477248 exceeds 10% of system memory.\n",
      "2024-10-19 10:26:43.571270: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 679477248 exceeds 10% of system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "   5/6300 [..............................] - ETA: 2:25:10 - loss: 0.6990 - acc: 0.4438 - mean_squared_error: 0.2416 - mean_absolute_error: 0.4828"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-19 10:26:48.754015: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 679477248 exceeds 10% of system memory.\n",
      "2024-10-19 10:26:48.754027: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 679477248 exceeds 10% of system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  10/6300 [..............................] - ETA: 2:06:06 - loss: 0.6143 - acc: 0.6455 - mean_squared_error: 0.1990 - mean_absolute_error: 0.4312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-19 10:26:53.973913: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 679477248 exceeds 10% of system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6300/6300 [==============================] - 6338s 1s/sample - loss: 0.1386 - acc: 0.8765 - mean_squared_error: 0.0288 - mean_absolute_error: 0.0694 - val_loss: 0.1289 - val_acc: 0.8826 - val_mean_squared_error: 0.0262 - val_mean_absolute_error: 0.0667\n",
      "Epoch 2/100\n",
      "6300/6300 [==============================] - 6324s 1s/sample - loss: 0.1285 - acc: 0.8795 - mean_squared_error: 0.0261 - mean_absolute_error: 0.0635 - val_loss: 0.1498 - val_acc: 0.8821 - val_mean_squared_error: 0.0262 - val_mean_absolute_error: 0.0574\n",
      "Epoch 3/100\n",
      "6300/6300 [==============================] - 6318s 1s/sample - loss: 0.1265 - acc: 0.8801 - mean_squared_error: 0.0256 - mean_absolute_error: 0.0623 - val_loss: 0.1277 - val_acc: 0.8832 - val_mean_squared_error: 0.0252 - val_mean_absolute_error: 0.0686\n",
      "Epoch 4/100\n",
      "6300/6300 [==============================] - 6319s 1s/sample - loss: 0.1249 - acc: 0.8805 - mean_squared_error: 0.0252 - mean_absolute_error: 0.0614 - val_loss: 0.1292 - val_acc: 0.8836 - val_mean_squared_error: 0.0254 - val_mean_absolute_error: 0.0715\n",
      "Epoch 5/100\n",
      "6300/6300 [==============================] - 6326s 1s/sample - loss: 0.1238 - acc: 0.8809 - mean_squared_error: 0.0249 - mean_absolute_error: 0.0607 - val_loss: 0.1243 - val_acc: 0.8838 - val_mean_squared_error: 0.0246 - val_mean_absolute_error: 0.0609\n",
      "Epoch 6/100\n",
      "6300/6300 [==============================] - 6323s 1s/sample - loss: 0.1227 - acc: 0.8813 - mean_squared_error: 0.0245 - mean_absolute_error: 0.0601 - val_loss: 0.1204 - val_acc: 0.8836 - val_mean_squared_error: 0.0241 - val_mean_absolute_error: 0.0572\n",
      "Epoch 7/100\n",
      "6300/6300 [==============================] - 6321s 1s/sample - loss: 0.1218 - acc: 0.8816 - mean_squared_error: 0.0243 - mean_absolute_error: 0.0595 - val_loss: 0.1212 - val_acc: 0.8842 - val_mean_squared_error: 0.0240 - val_mean_absolute_error: 0.0572\n",
      "Epoch 8/100\n",
      "6300/6300 [==============================] - 6323s 1s/sample - loss: 0.1209 - acc: 0.8819 - mean_squared_error: 0.0240 - mean_absolute_error: 0.0589 - val_loss: 0.1214 - val_acc: 0.8852 - val_mean_squared_error: 0.0238 - val_mean_absolute_error: 0.0623\n",
      "Epoch 9/100\n",
      "6300/6300 [==============================] - 6319s 1s/sample - loss: 0.1202 - acc: 0.8822 - mean_squared_error: 0.0238 - mean_absolute_error: 0.0585 - val_loss: 0.1211 - val_acc: 0.8848 - val_mean_squared_error: 0.0236 - val_mean_absolute_error: 0.0528\n",
      "Epoch 10/100\n",
      "6300/6300 [==============================] - 6328s 1s/sample - loss: 0.1193 - acc: 0.8825 - mean_squared_error: 0.0235 - mean_absolute_error: 0.0579 - val_loss: 0.1253 - val_acc: 0.8840 - val_mean_squared_error: 0.0240 - val_mean_absolute_error: 0.0678\n",
      "Epoch 11/100\n",
      "6300/6300 [==============================] - 6326s 1s/sample - loss: 0.1186 - acc: 0.8827 - mean_squared_error: 0.0233 - mean_absolute_error: 0.0575 - val_loss: 0.1178 - val_acc: 0.8850 - val_mean_squared_error: 0.0232 - val_mean_absolute_error: 0.0565\n",
      "Epoch 12/100\n",
      "6300/6300 [==============================] - 6326s 1s/sample - loss: 0.1179 - acc: 0.8830 - mean_squared_error: 0.0231 - mean_absolute_error: 0.0570 - val_loss: 0.1163 - val_acc: 0.8857 - val_mean_squared_error: 0.0228 - val_mean_absolute_error: 0.0566\n",
      "Epoch 13/100\n",
      "6300/6300 [==============================] - 6342s 1s/sample - loss: 0.1172 - acc: 0.8832 - mean_squared_error: 0.0229 - mean_absolute_error: 0.0566 - val_loss: 0.1163 - val_acc: 0.8851 - val_mean_squared_error: 0.0228 - val_mean_absolute_error: 0.0567\n",
      "Epoch 14/100\n",
      "6300/6300 [==============================] - 6356s 1s/sample - loss: 0.1167 - acc: 0.8835 - mean_squared_error: 0.0227 - mean_absolute_error: 0.0562 - val_loss: 0.1149 - val_acc: 0.8865 - val_mean_squared_error: 0.0224 - val_mean_absolute_error: 0.0549\n",
      "Epoch 15/100\n",
      "6300/6300 [==============================] - 6356s 1s/sample - loss: 0.1162 - acc: 0.8836 - mean_squared_error: 0.0226 - mean_absolute_error: 0.0559 - val_loss: 0.1222 - val_acc: 0.8857 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.0657\n",
      "Epoch 16/100\n",
      "6300/6300 [==============================] - 6341s 1s/sample - loss: 0.1156 - acc: 0.8838 - mean_squared_error: 0.0224 - mean_absolute_error: 0.0555 - val_loss: 0.1150 - val_acc: 0.8867 - val_mean_squared_error: 0.0224 - val_mean_absolute_error: 0.0553\n",
      "Epoch 17/100\n",
      "6300/6300 [==============================] - 6339s 1s/sample - loss: 0.1153 - acc: 0.8839 - mean_squared_error: 0.0223 - mean_absolute_error: 0.0553 - val_loss: 0.1138 - val_acc: 0.8865 - val_mean_squared_error: 0.0221 - val_mean_absolute_error: 0.0544\n",
      "Epoch 18/100\n",
      "6300/6300 [==============================] - 6350s 1s/sample - loss: 0.1148 - acc: 0.8841 - mean_squared_error: 0.0222 - mean_absolute_error: 0.0550 - val_loss: 0.1139 - val_acc: 0.8865 - val_mean_squared_error: 0.0221 - val_mean_absolute_error: 0.0545\n",
      "Epoch 19/100\n",
      "6300/6300 [==============================] - 6347s 1s/sample - loss: 0.1143 - acc: 0.8843 - mean_squared_error: 0.0220 - mean_absolute_error: 0.0547 - val_loss: 0.1192 - val_acc: 0.8853 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.0623\n",
      "Epoch 20/100\n",
      "6300/6300 [==============================] - 6334s 1s/sample - loss: 0.1140 - acc: 0.8844 - mean_squared_error: 0.0219 - mean_absolute_error: 0.0545 - val_loss: 0.1144 - val_acc: 0.8868 - val_mean_squared_error: 0.0222 - val_mean_absolute_error: 0.0528\n",
      "Epoch 21/100\n",
      "6300/6300 [==============================] - 6331s 1s/sample - loss: 0.1137 - acc: 0.8845 - mean_squared_error: 0.0219 - mean_absolute_error: 0.0543 - val_loss: 0.1148 - val_acc: 0.8863 - val_mean_squared_error: 0.0222 - val_mean_absolute_error: 0.0563\n",
      "Epoch 22/100\n",
      "6300/6300 [==============================] - 6336s 1s/sample - loss: 0.1134 - acc: 0.8846 - mean_squared_error: 0.0218 - mean_absolute_error: 0.0541 - val_loss: 0.1153 - val_acc: 0.8859 - val_mean_squared_error: 0.0223 - val_mean_absolute_error: 0.0552\n",
      "Epoch 23/100\n",
      "6300/6300 [==============================] - 6360s 1s/sample - loss: 0.1114 - acc: 0.8853 - mean_squared_error: 0.0212 - mean_absolute_error: 0.0529 - val_loss: 0.1112 - val_acc: 0.8876 - val_mean_squared_error: 0.0214 - val_mean_absolute_error: 0.0528\n",
      "Epoch 24/100\n",
      "6300/6300 [==============================] - 6363s 1s/sample - loss: 0.1110 - acc: 0.8854 - mean_squared_error: 0.0211 - mean_absolute_error: 0.0526 - val_loss: 0.1111 - val_acc: 0.8876 - val_mean_squared_error: 0.0213 - val_mean_absolute_error: 0.0528\n",
      "Epoch 25/100\n",
      "6300/6300 [==============================] - 6361s 1s/sample - loss: 0.1109 - acc: 0.8854 - mean_squared_error: 0.0210 - mean_absolute_error: 0.0525 - val_loss: 0.1112 - val_acc: 0.8876 - val_mean_squared_error: 0.0213 - val_mean_absolute_error: 0.0518\n",
      "Epoch 26/100\n",
      "6300/6300 [==============================] - 6363s 1s/sample - loss: 0.1107 - acc: 0.8855 - mean_squared_error: 0.0210 - mean_absolute_error: 0.0524 - val_loss: 0.1109 - val_acc: 0.8875 - val_mean_squared_error: 0.0213 - val_mean_absolute_error: 0.0527\n",
      "Epoch 27/100\n",
      "6300/6300 [==============================] - 6366s 1s/sample - loss: 0.1106 - acc: 0.8855 - mean_squared_error: 0.0209 - mean_absolute_error: 0.0524 - val_loss: 0.1109 - val_acc: 0.8874 - val_mean_squared_error: 0.0213 - val_mean_absolute_error: 0.0531\n",
      "Epoch 28/100\n",
      "4240/6300 [===================>..........] - ETA: 33:19 - loss: 0.1104 - acc: 0.8856 - mean_squared_error: 0.0209 - mean_absolute_error: 0.0522"
     ]
    }
   ],
   "source": [
    "# Define some callbacks to improve training.\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5)\n",
    "# Define modifiable training hyperparameters.\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 5\n",
    "\n",
    "# Fit the model to the training data.\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "model.save(os.path.join(output_dir, \"WP_12framesconvLSTM_overlap_d2.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194abc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.title(\"Model Loss\", fontsize=25)\n",
    "plt.xlabel(\"Epoch\", fontsize=20)\n",
    "plt.ylabel(\"Loss\", fontsize=20)\n",
    "plt.legend(loc = \"upper right\", fontsize=15)\n",
    "plt.savefig(os.path.join(output_dir, \"WP_12framesconvLSTM_overlap_loss_d3.png\"))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history[\"acc\"], label=\"Train Accuracy\")\n",
    "plt.plot(history.history[\"val_acc\"], label=\"Validation Accuracy\")\n",
    "plt.title(\"Model Accuracy\", fontsize=25)\n",
    "plt.xlabel(\"Epoch\", fontsize=20)\n",
    "plt.ylabel(\"Accuracy\", fontsize=20)\n",
    "plt.legend(loc = \"lower right\", fontsize=15)\n",
    "plt.savefig(os.path.join(output_dir, \"WP_12framesconvLSTM_overlap_accuracy_d3.png\"))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history[\"mean_squared_error\"], label=\"Train MSE\")\n",
    "plt.plot(history.history[\"val_mean_squared_error\"], label=\"Validation MSE\")\n",
    "plt.title(\"Model Mean Squared Error\", fontsize=25)\n",
    "plt.xlabel(\"Epoch\", fontsize=20)\n",
    "plt.ylabel(\"Mean Squared Error\", fontsize=20)\n",
    "plt.legend(loc = \"upper right\", fontsize=15)\n",
    "plt.savefig(os.path.join(output_dir, \"WP_12framesconvLSTM_overlap_mse_d3.png\"))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history[\"mean_absolute_error\"], label=\"Train MAE\")\n",
    "plt.plot(history.history[\"val_mean_absolute_error\"], label=\"Validation MAE\")\n",
    "plt.title(\"Model Mean Absolute Error\", fontsize=25)\n",
    "plt.xlabel(\"Epoch\", fontsize=20)\n",
    "plt.ylabel(\"Mean Absolute Error\", fontsize=20)\n",
    "plt.legend(loc = \"upper right\", fontsize=15)\n",
    "plt.savefig(os.path.join(output_dir, \"WP_12framesconvLSTM_overlap_mae_d3.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523cc0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_train_acc = np.mean(history.history[\"acc\"])\n",
    "avg_val_acc = np.mean(history.history[\"val_acc\"])\n",
    "avg_mse = np.mean(history.history[\"mean_squared_error\"])\n",
    "avg_val_mse = np.mean(history.history[\"val_mean_squared_error\"])\n",
    "avg_mae = np.mean(history.history[\"mean_absolute_error\"])\n",
    "avg_val_mae = np.mean(history.history[\"val_mean_absolute_error\"])\n",
    "\n",
    "print(\"Average Training Accuracy: \" + str(avg_train_acc))\n",
    "print(\"Average Validation Accuracy: \" + str(avg_val_acc))\n",
    "print(\"Average Training MSE: \" + str(avg_mse))\n",
    "print(\"Average Validation MSE: \" + str(avg_val_mse))\n",
    "print(\"Average Training MAE: \" + str(avg_mae))\n",
    "print(\"Average Validation MAE: \" + str(avg_val_mae))\n",
    "\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "print(predictions.shape)\n",
    "print(\"Number of predicted frames:\" + str(len(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcf1574",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b881d2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a few random examples from the dataset.\n",
    "# example = test_dataset[np.random.choice(range(len(test_dataset)), size=1)[0]]\n",
    "# print(example.shape)\n",
    "\n",
    "# select a fixed example index\n",
    "example_index = 13   # Change as needed\n",
    "example = test_dataset[example_index]\n",
    "print(example.shape)\n",
    "\n",
    "# Pick the first/last ten frames from the example.\n",
    "frames = example[:12, ...]\n",
    "original_frames = example[12:, ...]\n",
    "\n",
    "# predict the next 18 fames\n",
    "new_prediction = model.predict(np.expand_dims(frames, axis=0))\n",
    "new_prediction = np.squeeze(new_prediction, axis=0)\n",
    "\n",
    "# Print the dimensions of your images\n",
    "print(\"Original Frames Shape:\", original_frames.shape)\n",
    "print(\"New Prediction Shape:\", new_prediction.shape)\n",
    "\n",
    "# Reshape and preprocess your data if needed\n",
    "new_prediction = new_prediction.reshape((-1, 64, 64, 1))\n",
    "original_frames = original_frames.reshape((-1, 64, 64, 1))\n",
    "\n",
    "# Initialize variables\n",
    "batch_size = len(new_prediction)\n",
    "mse_total = 0\n",
    "mae_total = 0\n",
    "pmae_total = 0\n",
    "\n",
    "# Loop through each example in the batch\n",
    "for i in range(batch_size):\n",
    "    pmae = 0\n",
    "    for j in range(12):  # Assuming you want to evaluate the first 10 frames\n",
    "        mse_total += mean_squared_error(original_frames[i, j], new_prediction[i, j])\n",
    "        mae_total += mean_absolute_error(original_frames[i, j], new_prediction[i, j])\n",
    "        pmae += 1.0 - mean_absolute_error(original_frames[i, j], new_prediction[i, j])\n",
    "    pmae_total += pmae * 100\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mse_total / (batch_size * 12)\n",
    "mae = mae_total / (batch_size * 12)\n",
    "pmae_total = pmae_total / (batch_size * 12)\n",
    "\n",
    "print('MSE: ', mse)\n",
    "print('MAE: ', mae)\n",
    "print('PMAE: ', pmae_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2785cc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a few random examples from the dataset.\n",
    "# examples = test_dataset[np.random.choice(range(len(test_dataset)), size=5)]\n",
    "\n",
    "# Select fixed examples (e.g., first 5 samples)\n",
    "# You can either use specific indices like:\n",
    "fixed_indices = [1, 4, 11, 21, 25]  # Change as needed\n",
    "\n",
    "examples = test_dataset[fixed_indices]  # Select those examples\n",
    "\n",
    "\n",
    "\n",
    "# Iterate over the examples and predict the frames.\n",
    "predicted_videos = []\n",
    "for example in examples:\n",
    "    # Pick the first/last ten frames from the example.\n",
    "    frames = example[:12, ...]\n",
    "    original_frames = example[12:, ...]\n",
    "    new_predictions = np.zeros(shape=(12, *frames[0].shape))\n",
    "\n",
    "    # Predict a new set of 10 frames.\n",
    "    for i in range(12):\n",
    "        # Extract the model's prediction and post-process it.\n",
    "        frames = example[: 12 + i + 1, ...]\n",
    "        new_prediction = model.predict(np.expand_dims(frames, axis=0))\n",
    "        new_prediction = np.squeeze(new_prediction, axis=0)\n",
    "        predicted_frame = np.expand_dims(new_prediction[-1, ...], axis=0)\n",
    "\n",
    "        # Extend the set of prediction frames.\n",
    "        new_predictions[i] = predicted_frame\n",
    "\n",
    "    # Create and save GIFs for each of the ground truth/prediction images.\n",
    "    for frame_set in [original_frames, new_predictions]:\n",
    "        # Construct a GIF from the selected video frames.\n",
    "        current_frames = np.squeeze(frame_set)\n",
    "        current_frames = (current_frames * 255).astype(np.uint8)\n",
    "\n",
    "        # Construct a GIF from the frames.\n",
    "        with io.BytesIO() as gif:\n",
    "            imageio.mimsave(gif, current_frames, \"GIF\", fps=5)\n",
    "            predicted_videos.append(gif.getvalue())\n",
    "\n",
    "# Display the videos.\n",
    "print(\"Truth\\tPrediction\")\n",
    "for i in range(0, len(predicted_videos), 2):\n",
    "    # Construct and display an `HBox` with the ground truth and prediction.\n",
    "    box = HBox(\n",
    "        [\n",
    "            widgets.Image(value=predicted_videos[i], layout=Layout(width='150px', height='150px')),\n",
    "            widgets.Image(value=predicted_videos[i + 1], layout=Layout(width='150px', height='150px')),\n",
    "        ]\n",
    "    )\n",
    "    display(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f81aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Select a random example from the validation dataset.\n",
    "# example = test_dataset[np.random.choice(range(len(test_dataset)), size=1)[0]]\n",
    "\n",
    "# Choose a specific example from the validation dataset (e.g., index 0)\n",
    "example_index = 4  # Change this to the desired index\n",
    "example = test_dataset[example_index]\n",
    "\n",
    "# Pick the first/last ten frames from the example.\n",
    "frames = example[:12, ...]\n",
    "original_frames = example[12:, ...]\n",
    "\n",
    "# Predict a new set of 10 frames.\n",
    "for _ in range(12):\n",
    "    # Extract the model's prediction and post-process it.\n",
    "    new_prediction = model.predict(np.expand_dims(frames, axis=0))\n",
    "    new_prediction = np.squeeze(new_prediction, axis=0)\n",
    "    predicted_frame = np.expand_dims(new_prediction[-1, ...], axis=0)\n",
    "\n",
    "    # Extend the set of prediction frames.\n",
    "    frames = np.concatenate((frames, predicted_frame), axis=0)\n",
    "\n",
    " # Evaluate the model\n",
    "# accuracy = mean_squared_error(original_frames, frames)\n",
    "\n",
    "# # Print the evaluation metrics\n",
    "# print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "# Construct a figure for the original and new frames.\n",
    "fig, axes = plt.subplots(2, 12, figsize=(20, 4))\n",
    "\n",
    "# Plot the original frames.\n",
    "for idx, ax in enumerate(axes[0]):\n",
    "    ax.imshow(original_frames[idx])\n",
    "    ax.set_title(f\"Frame {idx + 13}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# Plot the new frames.\n",
    "new_frames = frames[12:, ...]\n",
    "for idx, ax in enumerate(axes[1]):\n",
    "    ax.imshow(new_frames[idx])\n",
    "    ax.set_title(f\"Frame {idx + 13}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# Display the figure.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd78c90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
